{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with RBF Kernel for Classification of Ethnic Origin Based on Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cd984c374773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Train the pipeline and predict on the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbf_kernel__sigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm__C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_sq_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_sq_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class RBFKernel(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, sigma=1):\n",
    "        super(RBFKernel, self).__init__()\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def transform(self, D_sq, **transform_params):\n",
    "        return np.exp(-D_sq / (2 * self.sigma ** 2))\n",
    "\n",
    "    def fit(self, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "# Define the pipeline.\n",
    "pipeline = Pipeline([\n",
    "    (\"rbf_kernel\", RBFKernel()),\n",
    "    (\"svm\", SVC(kernel=\"precomputed\")),\n",
    "])\n",
    "\n",
    "# Suppose there is some code here to load the pairwise distance matrix and ground truth.\n",
    "# Load ground truth.\n",
    "PATH = \"/home/ubuntu/one-k-genomes/\"\n",
    "sample_data_file = \"{:s}data/sample_data/sample_data.tsv\".format(PATH)\n",
    "df = pd.read_csv(sample_data_file, sep='\\t', index_col=0)\n",
    "\n",
    "# Get list of populations.\n",
    "pops = df[\"Population\"].tolist()\n",
    "unique_pops = list(set(pops))\n",
    "unique_pops.sort()\n",
    "num_pops = len(pops)\n",
    "\n",
    "# Create population dictionaries and ground truth.\n",
    "pop_to_num = dict(zip(unique_pops, range(num_pops)))\n",
    "num_to_pop = dict(zip(range(num_pops), unique_pops))\n",
    "Y = np.array([pop_to_num[pop] for pop in pops])\n",
    "\n",
    "# Get dictionary for population descriptions.\n",
    "population_file = \"{:s}data/sample_data/populations.tsv\".format(PATH)\n",
    "df = pd.read_csv(population_file, sep='\\t')\n",
    "code_to_descrip = dict(zip(\n",
    "    df[\"Population Code\"].tolist(),\n",
    "    df[\"Population Description\"].tolist(),\n",
    "))\n",
    "\n",
    "# Pairwise distance.\n",
    "pdist_file = \"{:s}data/pdist/summed_mats/pdist_num.npy\".format(PATH)\n",
    "D_sq = np.load(pdist_file)\n",
    "m = D_sq.shape[0]\n",
    "\n",
    "# Create an 80-20 train-test split.\n",
    "m = D_sq.shape[0]\n",
    "num_train = round(0.2 * m)\n",
    "D_sq_train = D_sq[:num_train, :num_train]\n",
    "D_sq_test = D_sq[num_train:, :num_train]\n",
    "Y_train = Y[:num_train]\n",
    "Y_test = Y[num_train:]\n",
    "\n",
    "# Train the pipeline and predict on the test set.\n",
    "pipeline.set_params(rbf_kernel__sigma=1, svm__C=1).fit(D_sq_train, Y_train)\n",
    "Y_pred = pipeline.predict(D_sq_test)\n",
    "accuracy = accuracy_score(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth.\n",
    "PATH = \"/home/ubuntu/one-k-genomes/\"\n",
    "sample_data_file = \"{:s}data/sample_data/sample_data.tsv\".format(PATH)\n",
    "df = pd.read_csv(sample_data_file, sep='\\t', index_col=0)\n",
    "\n",
    "# Get list of populations.\n",
    "pops = df[\"Population\"].tolist()\n",
    "unique_pops = list(set(pops))\n",
    "unique_pops.sort()\n",
    "num_pops = len(pops)\n",
    "\n",
    "# Create population dictionaries and ground truth.\n",
    "pop_to_num = dict(zip(unique_pops, range(num_pops)))\n",
    "num_to_pop = dict(zip(range(num_pops), unique_pops))\n",
    "Y = np.array([pop_to_num[pop] for pop in pops])\n",
    "\n",
    "# Get dictionary for population descriptions.\n",
    "population_file = \"{:s}data/sample_data/populations.tsv\".format(PATH)\n",
    "df = pd.read_csv(population_file, sep='\\t')\n",
    "code_to_descrip = dict(zip(\n",
    "    df[\"Population Code\"].tolist(),\n",
    "    df[\"Population Description\"].tolist(),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute RBF Kernel\n",
    "\n",
    "The RBF kernel \\\\(K\\\\) is computed from the pairwise distance matrix \\\\(D_{sq}\\\\) by the formula\n",
    "\n",
    "\\\\[\n",
    "K = \\exp\\left(-\\frac{D_{sq}}{2 \\sigma^2}\\right),\n",
    "\\\\]\n",
    "\n",
    "where \\\\(\\sigma > 0\\\\) is a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelWrapper(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, sigma=1):\n",
    "        super(KernelWrapper, self).__init__()\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def transform(self, D_sq, **transform_params):\n",
    "        return np.exp(-D_sq / (2 * self.sigma ** 2))\n",
    "\n",
    "    def fit(self, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kern = KernelWrapper(sigma=1)\n",
    "temp = np.array([[1,2], [3,4]])\n",
    "temp_array = np.array([[5, 6]])\n",
    "test = kern.fit()\n",
    "kern.transform(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"kern\", KernelWrapper()),\n",
    "    (\"svm\", SVC(kernel=\"precomputed\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the linear kernel from the pairwise distance matrix.\n",
    "pdist_file = \"{:s}data/pdist/summed_mats/pdist_num.npy\".format(PATH)\n",
    "D_sq = np.load(pdist_file)\n",
    "m = D_sq.shape[0]\n",
    "\n",
    "cv_params = [\n",
    "    dict([\n",
    "        ('kern__sigma', 10.0 ** np.arange(-15, -1)),\n",
    "#        ('svm__kernel', ['precomputed']),\n",
    "        ('svm__C', 10.0**np.arange(-2, 9)),\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Use an 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly permute data.\n",
    "np.random.seed(0)\n",
    "rand_perm = np.random.permutation(m)\n",
    "D_sq = D_sq[rand_perm, :]\n",
    "D_sq = D_sq[:, rand_perm]\n",
    "Y = Y[rand_perm]\n",
    "\n",
    "# Create 80-20 train-test split.\n",
    "num_test = round(0.2 * m)\n",
    "num_train = m - num_test\n",
    "D_sq_train = D_sq[:num_train, :num_train]\n",
    "D_sq_test = D_sq[num_train:, :num_train]\n",
    "Y_train = Y[:num_train]\n",
    "Y_test = Y[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(D_sq_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GridSearchCV(pipeline, cv_params, cv=5, verbose=1, n_jobs=-1,\n",
    "                     iid=True, return_train_score=True)\n",
    "classifier.fit(D_sq_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation and Grid Search\n",
    "\n",
    "Search for optimal value of the regularization constant \\\\(C\\\\) using five-fold cross-validation and iterative grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'C': 10.0 ** np.arange(-6,4)}\n",
    "param_grid = {'C': np.linspace(1.0, 2.0, 11) * 1e-6}\n",
    "classifier = GridSearchCV(SVC(kernel=\"precomputed\"),\n",
    "                          cv=5,\n",
    "                          param_grid=param_grid,\n",
    "                          iid=True,\n",
    "                          return_train_score=True)\n",
    "classifier.fit(K_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results of Grid Search\n",
    "\n",
    "I chose the smallest value of \\\\(C\\\\) that maximized the mean validation accuracy (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(classifier.cv_results_)\n",
    "results_df = results_df[[\n",
    "    \"param_C\",\n",
    "    \"mean_train_score\",\n",
    "    \"mean_test_score\"\n",
    "]]\n",
    "results_df.sort_values(\n",
    "    by=[\"mean_test_score\"],\n",
    "    ascending=False,\n",
    "    inplace=True,\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.1e-6    # Regularization parameter.\n",
    "svc = SVC(kernel=\"precomputed\", C=C)\n",
    "svc.fit(K_train, Y_train)\n",
    "Y_pred = svc.predict(K_test)\n",
    "test_accuracy = accuracy_score(Y_pred, Y_test)\n",
    "Y_train_pred = svc.predict(K_train)\n",
    "train_accuracy = accuracy_score(Y_train_pred, Y_train)\n",
    "\n",
    "print(\"Test Accuracy: {:1.4f}\".format(test_accuracy))\n",
    "print(\"Train Accuracy: {:1.4f}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_ind = ~(Y_pred == Y_test)\n",
    "predicted = [code_to_descrip[num_to_pop[x]] for x in Y_pred[incorrect_ind]]\n",
    "ground_truth = [code_to_descrip[num_to_pop[x]] for x in Y_test[incorrect_ind]]\n",
    "df_ = pd.DataFrame({\n",
    "    \"Pred\": predicted,\n",
    "    \"GT\": ground_truth,\n",
    "})\n",
    "swap_ind = df_[\"Pred\"] > df_[\"GT\"]\n",
    "df_.loc[swap_ind, [\"Pred\", \"GT\"]] = df_.loc[swap_ind,[\"GT\", \"Pred\"]].values\n",
    "df_ = pd.DataFrame(df_.groupby([\"Pred\", \"GT\"]).size()).reset_index()\n",
    "df_.columns = [\"Class 1\", \"Class 2\", \"Error Count\"]\n",
    "df_.sort_values(by=\"Error Count\", ascending=False, inplace=True)\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some class labels are not mutually exclusive:\n",
    "\n",
    "- British in England and Scotland and Utah Residents with Northern and Western European Ancestry\n",
    "- African Ancestry in the Southwest US and African Caribbean in Barbados\n",
    "- African Caribbean in Bardados and Yoruba in Nigeria\n",
    "- Han Chinese in Beijing and Southern Han Chinese\n",
    "\n",
    "These four groups account for ~79% of the error on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
