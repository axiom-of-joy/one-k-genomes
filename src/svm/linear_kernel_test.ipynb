{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for Classification of Ethnic Origin Based on Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth.\n",
    "PATH = \"/home/ubuntu/one-k-genomes/\"\n",
    "sample_data_file = \"{:s}data/sample_data/sample_data.tsv\".format(PATH)\n",
    "df = pd.read_csv(sample_data_file, sep='\\t', index_col=0)\n",
    "\n",
    "# Get list of populations.\n",
    "pops = df[\"Population\"].tolist()\n",
    "unique_pops = list(set(pops))\n",
    "unique_pops.sort()\n",
    "num_pops = len(pops)\n",
    "\n",
    "# Create population dictionaries and ground truth.\n",
    "pop_to_num = dict(zip(unique_pops, range(num_pops)))\n",
    "num_to_pop = dict(zip(range(num_pops), unique_pops))\n",
    "Y = np.array([pop_to_num[pop] for pop in pops])\n",
    "\n",
    "# Get dictionary for population descriptions.\n",
    "population_file = \"{:s}data/sample_data/populations.tsv\".format(PATH)\n",
    "df = pd.read_csv(population_file, sep='\\t')\n",
    "code_to_descrip = dict(zip(\n",
    "    df[\"Population Code\"].tolist(),\n",
    "    df[\"Population Description\"].tolist(),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Linear Kernel\n",
    "\n",
    "The linear kernel \\\\(K\\\\) can be computed from the pairwise distance matrix \\\\(D_{sq}\\\\) by the formula\n",
    "\n",
    "\\\\[\n",
    "K = -\\left(I_m - \\frac{\\mathbf 1_{m \\times m}}{m}\\right) \\frac{D_{sq}}{2} \\left(I_m - \\frac{\\mathbf 1_{m \\times m}}{m}\\right).\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the linear kernel from the pairwise distance matrix.\n",
    "pdist_file = \"{:s}data/pdist/summed_mats/pdist_all.npy\".format(PATH)\n",
    "D_sq = np.load(pdist_file)\n",
    "m = D_sq.shape[0]\n",
    "A = np.eye(m) - np.ones((m, m)) / m\n",
    "K = - A @ (D_sq / 2) @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Use an 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9e75f0b2f779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_perm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_perm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mY_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_sp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_perm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create 80-20 train-test split.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# Randomly permute data.\n",
    "np.random.seed(0)\n",
    "rand_perm = np.random.permutation(m)\n",
    "K = K[rand_perm, :]\n",
    "K = K[:, rand_perm]\n",
    "Y = Y[rand_perm]\n",
    "\n",
    "# Create 80-20 train-test split.\n",
    "num_test = round(0.2 * m)\n",
    "num_train = m - num_test\n",
    "K_train = K[:num_train, :num_train]\n",
    "K_test = K[num_train:, :num_train]\n",
    "Y_train = Y[:num_train]\n",
    "Y_test = Y[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation and Grid Search\n",
    "\n",
    "Search for optimal value of the regularization constant \\\\(C\\\\) using five-fold cross-validation and iterative grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='precomputed', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=None,\n",
       "       param_grid={'C': array([1.0e-06, 1.1e-06, 1.2e-06, 1.3e-06, 1.4e-06, 1.5e-06, 1.6e-06,\n",
       "       1.7e-06, 1.8e-06, 1.9e-06, 2.0e-06])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#param_grid = {'C': 10.0 ** np.arange(-6,4)}\n",
    "param_grid = {'C': np.linspace(1.0, 2.0, 11) * 1e-6}\n",
    "classifier = GridSearchCV(SVC(kernel=\"precomputed\"),\n",
    "                          cv=5,\n",
    "                          param_grid=param_grid,\n",
    "                          iid=True,\n",
    "                          return_train_score=True)\n",
    "classifier.fit(K_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results of Grid Search\n",
    "\n",
    "I chose the smallest value of \\\\(C\\\\) that maximized the mean validation accuracy (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.7e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.8e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.9e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C  mean_train_score  mean_test_score\n",
       "1   1.1e-06               1.0         0.864204\n",
       "2   1.2e-06               1.0         0.864204\n",
       "3   1.3e-06               1.0         0.864204\n",
       "4   1.4e-06               1.0         0.864204\n",
       "5   1.5e-06               1.0         0.864204\n",
       "6   1.6e-06               1.0         0.864204\n",
       "7   1.7e-06               1.0         0.864204\n",
       "8   1.8e-06               1.0         0.864204\n",
       "9   1.9e-06               1.0         0.864204\n",
       "10    2e-06               1.0         0.864204\n",
       "0     1e-06               1.0         0.863704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(classifier.cv_results_)\n",
    "results_df = results_df[[\n",
    "    \"param_C\",\n",
    "    \"mean_train_score\",\n",
    "    \"mean_test_score\"\n",
    "]]\n",
    "results_df.sort_values(\n",
    "    by=[\"mean_test_score\"],\n",
    "    ascending=False,\n",
    "    inplace=True,\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9042\n",
      "Train Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "C = 1.1e-6    # Regularization parameter.\n",
    "svc = SVC(kernel=\"precomputed\", C=C)\n",
    "svc.fit(K_train, Y_train)\n",
    "Y_pred = svc.predict(K_test)\n",
    "test_accuracy = accuracy_score(Y_pred, Y_test)\n",
    "Y_train_pred = svc.predict(K_train)\n",
    "train_accuracy = accuracy_score(Y_train_pred, Y_train)\n",
    "\n",
    "print(\"Test Accuracy: {:1.4f}\".format(test_accuracy))\n",
    "print(\"Train Accuracy: {:1.4f}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Error Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British in England and Scotland</td>\n",
       "      <td>Utah residents with Northern and Western Europ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African Ancestry in Southwest US</td>\n",
       "      <td>African Caribbean in Barbados</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Indian Telugu in the UK</td>\n",
       "      <td>Sri Lankan Tamil in the UK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colombian in Medellin, Colombia</td>\n",
       "      <td>Mexican Ancestry in Los Angeles, California</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African Caribbean in Barbados</td>\n",
       "      <td>Yoruba in Ibadan, Nigeria</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bengali in Bangladesh</td>\n",
       "      <td>Sri Lankan Tamil in the UK</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Han Chinese in Bejing, China</td>\n",
       "      <td>Southern Han Chinese, China</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Esan in Nigeria</td>\n",
       "      <td>Yoruba in Ibadan, Nigeria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gujarati Indian in Houston,TX</td>\n",
       "      <td>Punjabi in Lahore,Pakistan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Han Chinese in Bejing, China</td>\n",
       "      <td>Japanese in Tokyo, Japan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iberian populations in Spain</td>\n",
       "      <td>Puerto Rican in Puerto Rico</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indian Telugu in the UK</td>\n",
       "      <td>Punjabi in Lahore,Pakistan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Punjabi in Lahore,Pakistan</td>\n",
       "      <td>Sri Lankan Tamil in the UK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Class 1  \\\n",
       "3    British in England and Scotland   \n",
       "0   African Ancestry in Southwest US   \n",
       "11           Indian Telugu in the UK   \n",
       "4    Colombian in Medellin, Colombia   \n",
       "1      African Caribbean in Barbados   \n",
       "2              Bengali in Bangladesh   \n",
       "8       Han Chinese in Bejing, China   \n",
       "5                    Esan in Nigeria   \n",
       "6      Gujarati Indian in Houston,TX   \n",
       "7       Han Chinese in Bejing, China   \n",
       "9       Iberian populations in Spain   \n",
       "10           Indian Telugu in the UK   \n",
       "12        Punjabi in Lahore,Pakistan   \n",
       "\n",
       "                                              Class 2  Error Count  \n",
       "3   Utah residents with Northern and Western Europ...           11  \n",
       "0                       African Caribbean in Barbados           10  \n",
       "11                         Sri Lankan Tamil in the UK            8  \n",
       "4         Mexican Ancestry in Los Angeles, California            4  \n",
       "1                           Yoruba in Ibadan, Nigeria            3  \n",
       "2                          Sri Lankan Tamil in the UK            3  \n",
       "8                         Southern Han Chinese, China            3  \n",
       "5                           Yoruba in Ibadan, Nigeria            1  \n",
       "6                          Punjabi in Lahore,Pakistan            1  \n",
       "7                            Japanese in Tokyo, Japan            1  \n",
       "9                         Puerto Rican in Puerto Rico            1  \n",
       "10                         Punjabi in Lahore,Pakistan            1  \n",
       "12                         Sri Lankan Tamil in the UK            1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_ind = ~(Y_pred == Y_test)\n",
    "predicted = [code_to_descrip[num_to_pop[x]] for x in Y_pred[incorrect_ind]]\n",
    "ground_truth = [code_to_descrip[num_to_pop[x]] for x in Y_test[incorrect_ind]]\n",
    "df_ = pd.DataFrame({\n",
    "    \"Pred\": predicted,\n",
    "    \"GT\": ground_truth,\n",
    "})\n",
    "swap_ind = df_[\"Pred\"] > df_[\"GT\"]\n",
    "df_.loc[swap_ind, [\"Pred\", \"GT\"]] = df_.loc[swap_ind,[\"GT\", \"Pred\"]].values\n",
    "df_ = pd.DataFrame(df_.groupby([\"Pred\", \"GT\"]).size()).reset_index()\n",
    "df_.columns = [\"Class 1\", \"Class 2\", \"Error Count\"]\n",
    "df_.sort_values(by=\"Error Count\", ascending=False, inplace=True)\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some class labels are not mutually exclusive:\n",
    "\n",
    "- British in England and Scotland and Utah Residents with Northern and Western European Ancestry\n",
    "- African Ancestry in the Southwest US and African Caribbean in Barbados\n",
    "- African Caribbean in Bardados and Yoruba in Nigeria\n",
    "- Han Chinese in Beijing and Southern Han Chinese\n",
    "\n",
    "These four groups account for ~79% of the error on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
