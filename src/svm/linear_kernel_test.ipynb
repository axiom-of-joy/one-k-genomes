{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Linear Kernel for Classification of Ethnic Origin Based on Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth.\n",
    "PATH = \"/home/ubuntu/one-k-genomes/\"\n",
    "sample_data_file = \"{:s}data/sample_data/sample_data.tsv\".format(PATH)\n",
    "df = pd.read_csv(sample_data_file, sep='\\t', index_col=0)\n",
    "\n",
    "# Get list of populations.\n",
    "pops = df[\"Population\"].tolist()\n",
    "unique_pops = list(set(pops))\n",
    "unique_pops.sort()\n",
    "num_pops = len(pops)\n",
    "\n",
    "# Create population dictionaries and ground truth.\n",
    "pop_to_num = dict(zip(unique_pops, range(num_pops)))\n",
    "num_to_pop = dict(zip(range(num_pops), unique_pops))\n",
    "Y = np.array([pop_to_num[pop] for pop in pops])\n",
    "\n",
    "# Get dictionary for population descriptions.\n",
    "population_file = \"{:s}data/sample_data/populations.tsv\".format(PATH)\n",
    "df = pd.read_csv(population_file, sep='\\t')\n",
    "code_to_descrip = dict(zip(\n",
    "    df[\"Population Code\"].tolist(),\n",
    "    df[\"Population Description\"].tolist(),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Linear Kernel\n",
    "\n",
    "The linear kernel \\\\(K\\\\) can be computed from the pairwise distance matrix \\\\(D_{sq}\\\\) by the formula\n",
    "\n",
    "\\\\[\n",
    "K = -\\left(I_m - \\frac{\\mathbf 1_{m \\times m}}{m}\\right) \\frac{D_{sq}}{2} \\left(I_m - \\frac{\\mathbf 1_{m \\times m}}{m}\\right).\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the linear kernel from the pairwise distance matrix.\n",
    "pdist_file = \"{:s}data/pdist/summed_mats/pdist_num.npy\".format(PATH)\n",
    "D_sq = np.load(pdist_file)\n",
    "m = D_sq.shape[0]\n",
    "A = np.eye(m) - np.ones((m, m)) / m\n",
    "K = - A @ (D_sq / 2) @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Use an 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly permute data.\n",
    "np.random.seed(0)\n",
    "rand_perm = np.random.permutation(m)\n",
    "K = K[rand_perm, :]\n",
    "K = K[:, rand_perm]\n",
    "Y = Y[rand_perm]\n",
    "\n",
    "# Create 80-20 train-test split.\n",
    "num_test = round(0.2 * m)\n",
    "num_train = m - num_test\n",
    "K_train = K[:num_train, :num_train]\n",
    "K_test = K[num_train:, :num_train]\n",
    "Y_train = Y[:num_train]\n",
    "Y_test = Y[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation and Grid Search\n",
    "\n",
    "Search for optimal value of the regularization constant \\\\(C\\\\) using five-fold cross-validation and iterative grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='precomputed', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=None,\n",
       "       param_grid={'C': array([7.0e-07, 7.1e-07, 7.2e-07, 7.3e-07, 7.4e-07, 7.5e-07, 7.6e-07,\n",
       "       7.7e-07, 7.8e-07, 7.9e-07, 8.0e-07])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#param_grid = {'C': 10.0 ** np.arange(-6,4)}\n",
    "param_grid = {'C': np.linspace(7.0, 8.0, 11) * 1e-7}\n",
    "classifier = GridSearchCV(SVC(kernel=\"precomputed\"),\n",
    "                          cv=5,\n",
    "                          param_grid=param_grid,\n",
    "                          iid=True,\n",
    "                          return_train_score=True)\n",
    "classifier.fit(K_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results of Grid Search\n",
    "\n",
    "I chose the smallest value of \\\\(C\\\\) that maximized the mean validation accuracy (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.9e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.7e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.883175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.5e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.882676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.6e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.882177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.879680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.3e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.878682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.1e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.877184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.876685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7e-07</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.876186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C  mean_train_score  mean_test_score\n",
       "9   7.9e-07          1.000000         0.884673\n",
       "10    8e-07          1.000000         0.884174\n",
       "8   7.8e-07          1.000000         0.883674\n",
       "7   7.7e-07          0.999874         0.883175\n",
       "5   7.5e-07          0.999874         0.882676\n",
       "6   7.6e-07          0.999874         0.882177\n",
       "4   7.4e-07          0.999874         0.879680\n",
       "3   7.3e-07          0.999874         0.878682\n",
       "1   7.1e-07          0.999874         0.877184\n",
       "2   7.2e-07          0.999874         0.876685\n",
       "0     7e-07          0.999874         0.876186"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(classifier.cv_results_)\n",
    "results_df = results_df[[\n",
    "    \"param_C\",\n",
    "    \"mean_train_score\",\n",
    "    \"mean_test_score\"\n",
    "]]\n",
    "results_df.sort_values(\n",
    "    by=[\"mean_test_score\"],\n",
    "    ascending=False,\n",
    "    inplace=True,\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9301\n",
      "Train Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "C = 7.9e-7    # Regularization parameter.\n",
    "svc = SVC(kernel=\"precomputed\", C=C)\n",
    "svc.fit(K_train, Y_train)\n",
    "Y_pred = svc.predict(K_test)\n",
    "test_accuracy = accuracy_score(Y_pred, Y_test)\n",
    "Y_train_pred = svc.predict(K_train)\n",
    "train_accuracy = accuracy_score(Y_train_pred, Y_train)\n",
    "\n",
    "print(\"Test Accuracy: {:1.4f}\".format(test_accuracy))\n",
    "print(\"Train Accuracy: {:1.4f}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Error Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African Ancestry in Southwest US</td>\n",
       "      <td>African Caribbean in Barbados</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indian Telugu in the UK</td>\n",
       "      <td>Sri Lankan Tamil in the UK</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colombian in Medellin, Colombia</td>\n",
       "      <td>Mexican Ancestry in Los Angeles, California</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British in England and Scotland</td>\n",
       "      <td>Utah residents with Northern and Western Europ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Han Chinese in Bejing, China</td>\n",
       "      <td>Southern Han Chinese, China</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African Caribbean in Barbados</td>\n",
       "      <td>Yoruba in Ibadan, Nigeria</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Esan in Nigeria</td>\n",
       "      <td>Yoruba in Ibadan, Nigeria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gujarati Indian in Houston,TX</td>\n",
       "      <td>Punjabi in Lahore,Pakistan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Han Chinese in Bejing, China</td>\n",
       "      <td>Japanese in Tokyo, Japan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iberian populations in Spain</td>\n",
       "      <td>Puerto Rican in Puerto Rico</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Telugu in the UK</td>\n",
       "      <td>Punjabi in Lahore,Pakistan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Punjabi in Lahore,Pakistan</td>\n",
       "      <td>Sri Lankan Tamil in the UK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Class 1  \\\n",
       "0   African Ancestry in Southwest US   \n",
       "10           Indian Telugu in the UK   \n",
       "3    Colombian in Medellin, Colombia   \n",
       "2    British in England and Scotland   \n",
       "7       Han Chinese in Bejing, China   \n",
       "1      African Caribbean in Barbados   \n",
       "4                    Esan in Nigeria   \n",
       "5      Gujarati Indian in Houston,TX   \n",
       "6       Han Chinese in Bejing, China   \n",
       "8       Iberian populations in Spain   \n",
       "9            Indian Telugu in the UK   \n",
       "11        Punjabi in Lahore,Pakistan   \n",
       "\n",
       "                                              Class 2  Error Count  \n",
       "0                       African Caribbean in Barbados           10  \n",
       "10                         Sri Lankan Tamil in the UK            7  \n",
       "3         Mexican Ancestry in Los Angeles, California            4  \n",
       "2   Utah residents with Northern and Western Europ...            3  \n",
       "7                         Southern Han Chinese, China            3  \n",
       "1                           Yoruba in Ibadan, Nigeria            2  \n",
       "4                           Yoruba in Ibadan, Nigeria            1  \n",
       "5                          Punjabi in Lahore,Pakistan            1  \n",
       "6                            Japanese in Tokyo, Japan            1  \n",
       "8                         Puerto Rican in Puerto Rico            1  \n",
       "9                          Punjabi in Lahore,Pakistan            1  \n",
       "11                         Sri Lankan Tamil in the UK            1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_ind = ~(Y_pred == Y_test)\n",
    "predicted = [code_to_descrip[num_to_pop[x]] for x in Y_pred[incorrect_ind]]\n",
    "ground_truth = [code_to_descrip[num_to_pop[x]] for x in Y_test[incorrect_ind]]\n",
    "df_ = pd.DataFrame({\n",
    "    \"Pred\": predicted,\n",
    "    \"GT\": ground_truth,\n",
    "})\n",
    "swap_ind = df_[\"Pred\"] > df_[\"GT\"]\n",
    "df_.loc[swap_ind, [\"Pred\", \"GT\"]] = df_.loc[swap_ind,[\"GT\", \"Pred\"]].values\n",
    "df_ = pd.DataFrame(df_.groupby([\"Pred\", \"GT\"]).size()).reset_index()\n",
    "df_.columns = [\"Class 1\", \"Class 2\", \"Error Count\"]\n",
    "df_.sort_values(by=\"Error Count\", ascending=False, inplace=True)\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some class labels are not mutually exclusive:\n",
    "\n",
    "- African Ancestry in the Southwest US and African Caribbean in Barbados\n",
    "- British in England and Scotland and Utah Residents with Northern and Western European Ancestry\n",
    "- Han Chinese in Beijing and Southern Han Chinese\n",
    "- African Caribbean in Bardados and Yoruba in Nigeria\n",
    "\n",
    "These four groups account for ~51% of the error on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
